{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "1IOok8-IzXW3IDffE4h7mtef5jz5cks57",
      "authorship_tag": "ABX9TyOk99QAYgOs/nVG23/eRM19",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrcichon/PoLLaMa-Adapted/blob/main/LLaMa_pl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8VR7acEVbp21"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!git clone https://github.com/ZrrSkywalker/LLaMA-Adapter.git\n",
        "!git clone https://github.com/mrcichon/PoLLaMa-Adapted\n",
        "!mv -f /content/PoLLaMa-Adapted/example.py /content/LLaMA-Adapter\n",
        "!pip install fairscale\n",
        "!pip install fire\n",
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install timm\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!torchrun --nproc_per_node 1 /content/LLaMA-Adapter/example.py \\\n",
        "         --ckpt_dir /PATH/TO/MODEL/DIR \\\n",
        "         --tokenizer_path /PATH/TO/TOKENIZER/tokenizer.model \\\n",
        "         --adapter_path /content/PoLLaMa-Adapted/adapter_adapter_len10_layer30_epoch5.pth"
      ],
      "metadata": {
        "id": "0o3gZLDH5l9c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}